\documentclass{ximera}
\input{../../../preamble.tex}

\author{Zack Reed}
%borrowed from selinger linear algebra
\title{Application to Voting Records: A Need for Separation}
\begin{document}
\begin{abstract}

\end{abstract}
\maketitle


% ----------------------------------------------------------------------
\subsection*{Application to U.S. Senate voting data}

The United States Senate%
\index{senate}%
\index{U.S. Senate}%
\index{United States Senate} votes on a lot of things: motions,
resolutions, amendments, and bills, among other things. Many of these
votes are roll call votes%
\index{voting}%
\index{roll call vote}, which means that the vote of every individual
senator is recorded (as opposed to a voice vote, where only the
outcome is recorded). Roll call data for the last 3 decades is
publicly available and can be downloaded from the U.S. Senate website
at \url{https://www.senate.gov/legislative/votes.htm}.

We will now explore how to use linear algebra, and in particular
principal component analysis, to gain some useful information from the
voting records.\footnote{This example was inspired by Examples~11.2.13
  and 11.3.15 of {\em ``Coding the Matrix: Linear Algebra through
    Computer Science Applications''} by Philip N. Klein.} I have made
a spreadsheet containing the votes of 99 senators for the first 200
roll call votes of 2007. Each row in the spreadsheet corresponds to a
senator, listed in alphabetical order from Daniel Akaka of Hawaii to
Ron Wyden of Oregon. I omitted one senator who died during 2007. Each
column of the spreadsheet corresponds to a vote. For example, the
first roll call vote of 2007 was on a resolution to honour President
Gerald Ford (it passed 88 to 0). Each cell of the spreadsheet contains
the number $1$ if the senator voted ``yes'', the number $-1$ if the
senator voted ``no'', and the number $0$ if the senator did not
vote. The spreadsheet is available from
\url{https://www.mathstat.dal.ca/~selinger/linear-algebra/} under
``Supplementary materials''. Here are the first few rows and columns
of the spreadsheet.
\begin{equation*}
  \begin{array}{|l|r|r|r|r|r|r|r|r}
    \hline
    \mbox{Akaka, Daniel (D) HI} & 1 & 1 & 1 & 1 & 1 & -1 & 1 & \ldots \\\hline
    \mbox{Alexander, Lamar (R) TN} & 0 & 1 & -1 & 1 & -1 & -1 & 1 & \ldots \\\hline
    \mbox{Allard, A. (R) CO} & 1 & 1 & -1 & -1 & -1 & 1 & 1 & \ldots \\\hline
    \mbox{Baucus, Max (D) MT} & 1 & 1 & 1 & 1 & 1 & -1 & 1 & \ldots \\\hline
    \mbox{Bayh, Evan (D) IN} & 1 & 1 & 1 & -1 & 1 & -1 & 1 & \ldots \\\hline
    \mbox{Bennett, Robert (R) UT} & 1 & 1 & -1 & 1 & 1 & -1 & 1 & \ldots \\\hline
    \mbox{\vdots} & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \ddots
  \end{array}
\end{equation*}
The human mind is not very well equipped to deal with such massive
amounts of data. Rather than listing 122 motions that Senator X
supported and 78 motions that she opposed, we like to come up with
abstractions, such as Senator X is ``conservative'', ``pro choice'',
``pro business'', ``hawkish'', etc. However, the problem with
abstractions is that they do not necessarily mean anything in the real
world. In the real world, a senator's record is just a sequence of
votes.

We will represent each senator by a vector in $\R^{200}$, which
corresponds to a row of the above table. For example, to Senator
Akaka, we associate the vector
\begin{equation*}
  \startmat{c} 1 \\ 1 \\ 1 \\ 1 \\ 1 \\ -1 \\ 1 \\ \vdots \stopmat
  \in\R^{200}.
\end{equation*}
Thus, we can represent each senator (or more precisely, each senator's
voting record) as a point in 200-dimensional space. In this way, the
voting data can be interpreted as $99$ points in $\R^{200}$.

Unfortunately, 200 dimensions are impossible to visualize. But what if
the voting records of all the senators lie on (or at least close to) a
much-smaller-dimensional affine subspace? This is actually not an
unreasonable expectation; after all, there are probably only a handful
of issues most senators care about. For example, if a certain senator
supports gun control, he will be likely to vote a certain way on
measures that affect gun control. If another senator supports the gun
lobby, she is likely to vote the opposite way.

We can thus consider this as an instance of the affine subspace
problem: we are looking for a low-dimensional affine subspace that is
close to all $99$ points. Following the method of
Proposition~\ref{prop:affine-subspace-fitting}, we first find the
centroid of the points, and then we compute a certain
$99\times 200$-matrix $A$ and a positive semidefinite
$200\times 200$-matrix $B=A^TA$. Using software, we can find the
eigenvalues and -vectors of $B$. The first few eigenvalues (in
decreasing order) are:
\begin{equation*}
  \eigenvar_1 = 7255.65,\quad
  \eigenvar_2 = 519.16,\quad
  \eigenvar_3 = 430.60,\quad
  \eigenvar_4 = 278.05,\quad\mbox{and}\quad
  \eigenvar_5 = 230.56.
\end{equation*}
All of the remaining eigenvalues are less than $200$, and the sum of
the remaining eigenvalues is
$\eigenvar_6+\ldots+\eigenvar_{200}=3913.46$. This means that the vast
majority of the voting behavior of each senator is determined by a
single dimension, given by the eigenvector corresponding to the
eigenvalue $\eigenvar_1$. In other words, there is a $1$-dimensional
affine subspace that all $99$ points are pretty close to. If we
project each senator to this affine subspace, we get the following
picture:

\begin{center}
  \includegraphics{pca_senate_1.png}
\end{center}

For convenience, Republican senators have been shown in red and
Democratic and independent senators in blue. Not all senators have
been named, because in some areas they are clustered very densely. An
interpretation of the principal component then immediately suggests
itself: it appears to be the ``conservative'' vs. ``liberal'' axis. We
can use this picture to assist in answering questions such as: {\em
  ``Which party votes more uniformly?''}, {\em ``Which state are the
  most liberal Republicans from?''}, {\em ``Which states are the most
  conservative Democrats from?''}, {\em ``Was Obama really a
  radical?''}, and {\em ``Was McCain really a maverick?''}.  If we
repeat the same calculation for the 2017 senate, we get the following
picture:

\begin{center}
  \includegraphics{pca_senate_2.png}
\end{center}

We can use this to help answer questions such as {\em ``Has the senate
  become more partisan between 2007 and 2017?''}.

If we instead project the data onto the first two principal
components, we get the following picture for the 2007 data:

\begin{center}
  \includegraphics{pca_senate_3.png}
\end{center}

The picture clearly shows senators clustering in certain areas. We can
use this to help answer certain questions, for example, {\em ``How
  different was Sanders's voting record from Clinton's?''}. However,
although the 2-dimensional picture seems to reveal more detail, its
interpretation is less clear. While it seems obvious that the
horizontal axis corresponds to a conservative vs.\ liberal world view,
it is much less obvious what the political meaning of the vertical
axis is. Maybe it is related to some issue that does not typically
follow party lines, such as North vs. South, rich states vs. poor
states, pro-immigration vs. anti-immigration, and so on.  To find a
convincing interpretation of the vertical axis, further investigation
of the data would be required (such as, looking at the actual content
of the votes in question).

Finally, a word of caution. Whenever we use mathematics to try to draw
real-world conclusions from data, these conclusions should be taken
with an extra-large grain of salt. People have an outsized tendency to
trust mathematics and to take its results as infallible. We therefore
have a special responsibility not to overstate any conclusions, and to
point out potential pitfalls with the analysis. No matter how
wonderful principal complement analysis is, we must keep in mind that
what we are still only looking at a 2-dimensional projection of a
200-dimensional space. Therefore it is inevitable that lots of details
and nuances are lost. We could get a completely different picture by
looking at a different 2-dimensional projection.

To see how the data can sometimes be misleading, consider the question
{\em ``How similar is Senator Tim Johnson, Democrat of South Dakota,
  to Senators Olympia Snowe and Susan Collins of Maine?''}. In the
1-dimensional picture, it looked as if they were very similar. We
could easily rationalize this by pointing out that Johnson is the most
conservative Democrat, and Snowe and Collins are the most liberal
Republicans. However, the 2-dimensional picture reveals an interesting
nuance, which is that the voting records of Johnson is not all that
similar to that of Snowe and Collins. It is entirely possible that if
we add a third or fourth dimension to the picture, many more
additional such details will emerge. In summary, while principal
component analysis is a useful tool, it is just one tool among many,
and we always need to exercise our best judgement in drawing
conclusions from data.


\end{document}