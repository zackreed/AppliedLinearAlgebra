\documentclass{ximera}
\input{../../../preamble.tex}

\author{Zack Reed}
%borrowed from selinger linear algebra
\title{The Characteristic Equation: Eigenvectors}
\begin{document}
\begin{abstract}

\end{abstract}
\maketitle

    
\subsection*{Eigenvectors}
Once we have computed an eigenvalue $\lambda$ of an $n \times n$ matrix $A$, the next step is to compute the associated eigenvectors.  In other words, we seek vectors $\vec{x}$ such that $A\vec{x}=\lambda \vec{x}$, or equivalently,
\begin{equation}\label{eqn:nullspace}
    (A-\lambda I) \vec{x}=\vec{0}  
\end{equation}
For any given eigenvalue $\lambda$ there are infinitely many eigenvectors associated with it. This underlies the notion of an eigenspace that was defined earlier. We again state the definition below.

    
\begin{definition}\label{def:eigspace}
The set of all eigenvectors associated with a given eigenvalue of a matrix is known as the \dfn{eigenspace} associated with that eigenvalue, and is a subspace of $\RR^n$.
\end{definition}
    
So given an eigenvalue $\lambda$, there is an associated eigenspace $\mathcal{S}$, and our goal is to find a basis of $\mathcal{S}$, for then any eigenvector $\vec{x}$ will be a linear combination of the vectors in that basis.  Moreover, we are trying to find a basis for the set of vectors that satisfy Equation \ref{eqn:nullspace}, which means we seek a basis for $\mbox{null}(A-\lambda I)$. 
    
Let's return to our previous examples to find eigenvectors for the matrices $A$, $B$, $C$, and $D$.
    
\begin{example}\label{ex:eigvect2x2eig} (Finding eigenvectors for Example \ref{ex:2x2eig} )
    
Recall that $A=\begin{bmatrix} 2& 1\\ 1&2
\end{bmatrix}$ has eigenvalues $\lambda_1=1$ and $\lambda_2=3$.  Compute a basis for the eigenspace associated with each of these eigenvalues.
\begin{explanation}
Eigenvectors associated with the eigenvalue $\lambda_1=1$ are in the null space of $A-I$.  So we seek a basis for $\mbox{null}(A-I)$.  We compute:
\begin{align*}\mbox{rref}(A-I)=\mbox{rref}\left(\begin{bmatrix}1&1\\1&1\end{bmatrix}\right)&=\begin{bmatrix}\answer{1}&\answer{1}\\\answer{0}&\answer{0}\end{bmatrix},
\end{align*}
From this we see that the eigenspace $\mathcal{S}_1$ associated with $\lambda_1=1$ consists of vectors of the form $\begin{bmatrix}\answer{-1}\\\answer{1}\end{bmatrix}t$.

This means that $\left\{\begin{bmatrix}\answer{-1}\\\answer{1}\end{bmatrix}\right\}$
is one possible basis for $\mathcal{S}_1$.
    
In a similar way, we compute a basis for $\mathcal{S}_3$, the subspace of all eigenvectors associated with the eigenvalue $\lambda_2=3$.  Now we compute:
\begin{align*}\mbox{rref}(A-3I)=\mbox{rref}\left(\begin{bmatrix}-1&1\\1&-1\end{bmatrix}\right)&=\begin{bmatrix}\answer{1}&\answer{-1}\\\answer{0}&\answer{0}\end{bmatrix},
\end{align*}
Vectors in the null space have the form $\begin{bmatrix}\answer{1}\\\answer{1}\end{bmatrix}t$.  So one possible basis for the eigenspace $\mathcal{S}_3$ is given by $\left\{\begin{bmatrix}\answer{1}\\\answer{1}\end{bmatrix}\right\}$.
\end{explanation}
\end{example}
    
\begin{example}\label{ex:eigvectors2x2eig2} (Finding eigenvectors for Example \ref{ex:2x2eig2})
We know from Example \ref{ex:2x2eig2} that $B=\begin{bmatrix} 2& 1\\ 4&2
\end{bmatrix}$ has eigenvalues $\lambda_1=0$ and $\lambda_2=4$.  Compute a basis for the eigenspace associated with each of these eigenvalues.
\begin{explanation}
Let's begin by finding a basis for the eigenspace $\mathcal{S}_0$, which is the subspace of $\RR^n$ consisting of eigenvectors corresponding to the eigenvalue $\lambda_1=0$.  We need to compute a basis for $\mbox{null}(B-0I) = \mbox{null}(B)$.  We compute:
\begin{align*}\mbox{rref}(B)=\mbox{rref}\left(\begin{bmatrix}2&1\\4&2\end{bmatrix}\right)&=\begin{bmatrix}\answer{1}&\answer{1/2}\\0&0\end{bmatrix},
\end{align*}
From this we see that an eigenvector in $\mathcal{S}_0$ has the form $\begin{bmatrix}\answer{-1/2}\\\answer{1}\end{bmatrix}t$.
This means that $\left\{\begin{bmatrix}\answer{-1/2}\\\answer{1}\end{bmatrix}\right\}$
     is one possible basis for the eigenspace $\mathcal{S}_0$.  By letting $t=-2$, we obtain an arbitrary but arguably nicer-looking basis: $\left\{\begin{bmatrix}\answer{1}\\\answer{-2}\end{bmatrix}\right\}$.

    
To compute a basis for $\mathcal{S}_4$, the subspace of all eigenvectors associated to the eigenvalue $\lambda_2=4$, we compute:
$$\mbox{rref}(B-4I)=\mbox{rref}\left(\begin{bmatrix}-2&1\\4&-2\end{bmatrix}\right)=\begin{bmatrix}\answer{1}&\answer{-1/2}\\0&0\end{bmatrix}$$

    
From this we find that $\left\{\begin{bmatrix}1\\\answer{2}\end{bmatrix}\right\}$ is one possible basis for the eigenspace $\mathcal{S}_4$.
\end{explanation}
\end{example}
    
\begin{example}\label{ex:eigvectors3x3eig} (Finding eigenvectors for Example \ref{ex:3x3eig})
    We know from Example \ref{ex:3x3eig} that $C=\begin{bmatrix} 2 & 1 & 1\\ 1 & 2 & 1\\ 1 & 1 & 2\end{bmatrix}$ has eigenvalues $\lambda_1=1$ and $\lambda_2=4$. Compute a basis for the eigenspace associated to each of these eigenvalues.
    \begin{explanation}
    We first find a basis for the eigenspace $\mathcal{S}_1$.  We need to compute a basis for $\mbox{null}(C-\answer{1}I)$.  We compute:
    \begin{align*}
    \mbox{rref}(C-\answer{1}I) &= \mbox{rref}\left(\begin{bmatrix} \answer{1} & \answer{1} & \answer{1}\\ \answer{1} & \answer{1} & \answer{1}\\ \answer{1} & \answer{1} & \answer{1}\end{bmatrix}\right) \\
    &= \begin{bmatrix} \answer{1} & \answer{1} & \answer{1}\\ 0 & 0 & 0\\ 0 & 0 & 0\end{bmatrix},
    \end{align*}
    Notice that there are two free variables. The eigenvectors in $\mathcal{S}_1$ have the form
    $$\begin{bmatrix}-s-t\\s\\t\end{bmatrix} = s\begin{bmatrix}-\answer{1}\\\answer{1}\\\answer{0}\end{bmatrix} + t\begin{bmatrix}-\answer{1}\\\answer{0}\\\answer{1}\end{bmatrix}$$
        
    So one possible basis for the eigenspace $\mathcal{S}_1$ is given by $\left\{\begin{bmatrix}-\answer{1}\\\answer{1}\\\answer{0}\end{bmatrix}, \begin{bmatrix}-\answer{1}\\\answer{0}\\\answer{1}\end{bmatrix}\right\}$.
        
    Next we find a basis for the eigenspace $\mathcal{S}_4$.  We need to compute a basis for $\mbox{null}(C-\answer{4}I)$.  We compute:
    \begin{align*}
    \mbox{rref}(C-\answer{4}I) &= \mbox{rref}\left(\begin{bmatrix} -\answer{2} & \answer{1} & \answer{1}\\ \answer{1} & -\answer{2} & \answer{1}\\ \answer{1} & \answer{1} & -\answer{2}\end{bmatrix}\right) \\
    &= \begin{bmatrix} \answer{1} & \answer{0} & -\answer{1}\\ 0 & \answer{1} & -\answer{1}\\ 0 & 0 & 0\end{bmatrix}
    \end{align*}
    This time there is one free variable. The eigenvectors in $\mathcal{S}_4$ have the form $\begin{bmatrix}\answer{1}\\\answer{1}\\\answer{1}\end{bmatrix}t$, so a possible basis for the eigenspace $\mathcal{S}_4$ is given by $\left\{\begin{bmatrix}\answer{1}\\\answer{1}\\\answer{1}\end{bmatrix}\right\}$.
    \end{explanation}
    \end{example}
    
    \begin{example}\label{ex:3x3_complex_ev} (Finding eigenvectors for Example \ref{ex:3x3_complex_eig})
        We know from Example \ref{ex:3x3_complex_eig} that $D=\begin{bmatrix} 0&0&0\\ 0 &1&1\\ 0 & -1&1\end{bmatrix}$ has eigenvalues $\lambda=0$, $\lambda_1=1+i$, and $\lambda_2=1-i$.  Compute a basis for the eigenspace associated with each eigenvalue.
        \begin{explanation}
        We first find a basis for the eigenspace $\mathcal{S}_0$.  We need to compute a basis for $\mbox{null}(D-\answer{0}I)=\mbox{null}(D)$.  We compute:
        \begin{align*}
        \mbox{rref}(D) &= \mbox{rref}\left(\begin{bmatrix} 0 & 0 & 0\\ 0 & 1 & 1\\ 0 & -1 & 1\end{bmatrix}\right) \\
        &= \begin{bmatrix} \answer{0} & \answer{1} & \answer{1}\\ \answer{0} & \answer{0} & \answer{1}\\ \answer{0} & \answer{0} & \answer{0}\end{bmatrix},
        \end{align*}
        From this we see that for any eigenvector $\begin{bmatrix}x_1\\x_2\\x_3\end{bmatrix}$ in $\mathcal{S}_0$ we have $x_2=\answer{0}$ and $x_3=\answer{0}$, but $x_1$ is a free variable.
        So one possible basis for the eigenspace $\mathcal{S}_0$ is given by $$\left\{\begin{bmatrix}\answer{1}\\\answer{0}\\\answer{0}\end{bmatrix}\right\}$$

        Next we find a basis for the eigenspace $\mathcal{S}_{1+i}$.  We need to compute a basis for $\mbox{null}(D-(1+i)I)$.  We compute:
        \begin{align*}
        \mbox{rref}(D-(1+i)I) &= \mbox{rref}\left(\begin{bmatrix} -(1+i)&0&0\\ 0 &1-(1+i)&1\\ 0 & -1&1-(1+i)\end{bmatrix}\right) \\
        &= \begin{bmatrix} \answer{1} & \answer{0} &\answer{0}\\ \answer{0} & \answer{1} & i\\ \answer{0} & \answer{0} & \answer{0}\end{bmatrix}
        \end{align*}
        There is one free variable.  Setting $x_3=t$, we get $x_1=\answer{0}$ and $x_2=ti$.  From this we see that eigenvectors in $\mathcal{S}_{1+i}$ have the form $\begin{bmatrix}\answer{0}\\i\\\answer{1}\end{bmatrix}t$, so a possible basis for the eigenspace $\mathcal{S}_{1+i}$ is given by $\left\{\begin{bmatrix}\answer{0}\\i\\\answer{1}\end{bmatrix}\right\}$.
        \end{explanation}
        \end{example}
    
We conclude this section by establishing the significance of a matrix having an eigenvalue of zero.
    
\begin{theorem}\label{th:zero_ew}
A square matrix has an eigenvalue of zero if and only if it is singular.
\end{theorem}
    
\begin{proof}
A square matrix $A$ is singular if and only if $\det{A}=0$.  But $\det{A}=0$ if and only if $\det{A-0I}=0$, which is true if and only if zero is an eigenvalue of $A$.
\end{proof}

    

\end{document}